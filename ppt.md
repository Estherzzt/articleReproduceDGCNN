æ¨è PPT ç»“æ„ï¼ˆ10â€“14 é¡µï¼‰
æˆ‘ç»™ä½ ä¸€ä¸ªå®ç”¨ç»“æ„ï¼Œæ¯ä¸€é¡µéƒ½å†™ä¸Šã€Œè¦è®²çš„é‡ç‚¹ã€ã€‚
â­ å°é¢é¡µ
Titleï¼šDGCNN Paper Reproduction â€” Understanding & Implementation
Name / Date
Mentor nameï¼ˆå¯é€‰ï¼‰
ğŸ‘‰ æ˜¾å¾—æ­£å¼
â­ Page 1 â€” Background & Task Objective
å†…å®¹è¦ç®€çŸ­ï¼š
What is the task?
3D Point Cloud Classification / Segmentation
Why DGCNN matters?
Local geometric relationships
Dynamic neighborhood learning
My task:
Reproduce code
Understand model
Run experiments & report insights
ğŸ‘‰ ç”¨ 3ï½4 bulletï¼Œä¸è¦å †å­—
â­ Page 2 â€” Paper Overviewï¼ˆæ ¸å¿ƒæ€æƒ³ï¼‰
å»ºè®®ç”» ä¸€å¼ é€»è¾‘å›¾ï¼ˆä½ è‡ªå·±ç”»å³å¯ï¼‰ï¼š
åŒ…æ‹¬ï¼š
è¾“å…¥ï¼šç‚¹äº‘ NÃ—3
KNN æ„å›¾
EdgeConv æå–è¾¹ç‰¹å¾
å¤šå±‚å †å 
Global pooling
å¹¶åŠ ä¸€å¥æ€»ç»“ï¼š
Key idea: Learn features on dynamic graphs instead of static neighborhoods.
ğŸ‘‰ è¿™ä¸€é¡µæ˜¯â€œå±•ç¤ºä½ ç†è§£è®ºæ–‡â€çš„å…³é”®
â­ Page 3 â€” EdgeConv Explainedï¼ˆå¿…é¡»è®²æ¸…ï¼‰
å†…å®¹ï¼š
edge feature = h(xi,xjâˆ’xi)
Preserve:
local geometry
translation awareness
Aggregation via max-pooling
å³ä¾§æ”¾ä¸€å°å¼ ç¤ºæ„æ¡†å›¾å³å¯ã€‚
ğŸ‘‰ è¿™ä¸€é¡µæ˜¯ mentor æœ€å¯èƒ½é—®é—®é¢˜çš„åœ°æ–¹
â­ Page 4 â€” Dynamic Graph vs Static Graph
ä¸¤æ å¯¹æ¯”è¡¨ï¼š
Static Graph	Dynamic Graph
fixed based on xyz	rebuilt per layer
same neighbors	feature-space neighbors
weak semantics	stronger semantics
æœ€åä¸€å¥æ€»ç»“ï¼š
Dynamic graph helps high-level semantic grouping.
ğŸ‘‰ ä½“ç°â€œç†è§£åˆ°ä½ï¼Œè€Œä¸æ˜¯æœºæ¢°å¤ç°â€
â­ Page 5 â€” Repository Structure (PyTorch Version)
åˆ—å‡º pytorch ç›®å½•å¯¹åº”å…³ç³»ï¼š
Component	File
Data loading	data.py
Model (EdgeConv)	model.py
Training loop	main.py
Utilities	util.py
å†åŠ ä¸€å¥ï¼š
I focused on PyTorch for main reproduction and understanding.
ğŸ‘‰ è¿™æ˜¯â€œä»£ç å±‚ç†è§£â€çš„èµ·ç‚¹
â­ Page 6 â€” Codeâ€“Paper Mappingï¼ˆåŠ åˆ†é¡µğŸ”¥ï¼‰
åšä¸€ä¸ªéå¸¸åŠ åˆ†çš„è¡¨ï¼š
Paper Concept	Code Implementation
EdgeConv	get_graph_feature() + EdgeConv()
Dynamic KNN	knn(x, k) called in each layer
Feature aggregation	concatenation across EdgeConv layers
Global representation	x.max(dim=2)
ğŸ‘‰ è¿™ä¸€é¡µå¯¼å¸ˆéå¸¸å–œæ¬¢
â­ Page 7 â€” Engineering Work I Didï¼ˆéå¸¸å…³é”®ï¼‰
è¿™ä¸€é¡µä¸€å®šè¦å†™ä½ â€œè‡ªå·±åšäº†ä»€ä¹ˆâ€ï¼š
Manual dataset preparation
Modify shell commands â†’ cross-platform (mac/Windows)
CPU-only environment setup
Small-scale sanity test
Logging & reproducibility scripts
ğŸ‘‰ è¿™æ˜¯æŠŠä½ ä»â€œå­¦ç”Ÿâ€å‡çº§åˆ°â€œå·¥ç¨‹å®ä¹ ç”Ÿâ€çš„åœ°æ–¹
â­ Page 8 â€” PyTorch Experiment Setupï¼ˆè®­ç»ƒä¸­å¯ç•™ç©ºï¼‰
å†…å®¹å¯ä»¥å…ˆå†™æ¡†æ¶ï¼Œç»“æœæ˜å¤©è¡¥ï¼š
ModelNet40
num_points=1024
k=20
optimizer: SGD
batch size / epochs
ç•™ä¸€ä¸ªå ä½ï¼š
Training in progressâ€¦
Test Accuracy:  xx.xx %  (to be filled)
Loss curve: (graph to insert)
ğŸ‘‰ ä½ å¯ä»¥ç­‰è®­ç»ƒç»“æŸå†è¡¥å›¾
â­ Page 9 â€” TensorFlow Version (Brief Study)
å†™ä¸‰ç‚¹å³å¯ï¼š
Static graph (session-based) pipeline
Similar model structure, different framework style
I ran a small-scale experiment to compare behavior
å¯ä»¥å†™ï¼š
I mainly used TF version for structural comparison, not full reproduction.
ğŸ‘‰ å±•ç° breadthï¼Œä¸ç”¨èŠ±å¤ªå¤šç¯‡å¹…
â­ Page 10 â€” Comparison PyTorch vs TensorFlowï¼ˆç®€çŸ­ï¼‰
PyTorch	TensorFlow
easier debugging	harder debugging
dynamic graph	static graph
better for research iteration	closer to early original code
I used for reproduction	I used for reference
ğŸ‘‰ å¯¼å¸ˆä¼šè§‰å¾—ä½ â€œæœ‰åˆ¤æ–­ã€æœ‰é€‰æ‹©â€
â­ Page 11 â€” What I Learned
å†™åæ€å‹æ€»ç»“ï¼š
Understanding graph-based feature learning
Difference between implementation & paper abstraction
Practical issues in reproducibility
Trade-off: CPU-only vs speed
ğŸ‘‰ æ˜¯ä¸€é¡µ æˆç†Ÿã€è¯šå®ã€æœ‰æ€è€ƒ çš„æ€»ç»“
â­ Page 12 â€” Next Stepsï¼ˆå¯¼å¸ˆè®¨è®ºå…¥å£ï¼‰
å†™ 3ï½4 æ¡å³å¯ï¼š
Ablation:
static vs dynamic graph
Try segmentation experiment
Visualize neighborhood evolution
Try larger-scale full training
ğŸ‘‰ ç»™ mentor æä¾›â€œè®¨è®ºè¯é¢˜â€
ğŸ› ï¸ ä½ ç°åœ¨å¯ä»¥è¿™æ ·å®‰æ’å·¥ä½œ
ä»Šæ™š / æ˜æ—©ï¼š
1ï¸âƒ£ å¼€å§‹è·‘ PyTorch 1024 full trainingï¼ˆCPUç‰ˆï¼‰
2ï¸âƒ£ è·‘ä¸€ä¸ª å°è§„æ¨¡ TensorFlow run
3ï¸âƒ£ åŒæ—¶å®Œæˆ PPT çš„å‰ 10 é¡µï¼ˆä¸å«ç»“æœï¼‰
ç­‰è®­ç»ƒå®Œæˆï¼š
4ï¸âƒ£ æŠŠï¼š
test accuracy
loss curve
few logs / screenshots
å¡«å…¥ Page 8

---
PPT Page 8 â€” PyTorch Experiment Setupï¼ˆå«å½“å‰æµ‹è¯•ç»“æœï¼‰
å¯ä»¥å…ˆè¿™æ ·å†™ï¼ˆè‹±æ–‡ç‰ˆï¼Œå¯¼å¸ˆçœ‹èµ·æ¥æ›´ä¸“ä¸šï¼‰ï¼š
Baseline Reproduction â€” PyTorch Implementation (Sanity Check Run)
Dataset: ModelNet40
num_points = 128 (reduced for quick testing)
k = 5
Batch size = 32 (CPU only)
Mode: Evaluation on a small test model (used only to verify pipeline correctness)
Device: CPU (no CUDA available)
Result (sanity-check run, not full training):
Test accuracy = 0.085
Test avg accuracy = 0.052
Purpose of this run:
Verify that the full pipeline works end-to-end
Confirm that dataset loading, model forward pass, evaluation loop, and checkpoint loading are all correct
This run uses very small num_points and k, so low accuracy is expected and does not reflect model performance.
ğŸ‘‰ è¿™æ®µè¯å¯ä»¥åŸæ ·æ”¾åˆ° PPT ä¸Š
ğŸ’¡ ä¸ºä»€ä¹ˆè¿™ä¸ªç»“æœâ€œä½ä½†åˆç†â€ï¼ˆå¯¼å¸ˆé—®åˆ°æ—¶å¯ä»¥è¿™ä¹ˆè¯´ï¼‰
ä½ å¯ä»¥åœ¨ PPT å¤‡æ³¨æˆ–è®²è§£æ—¶è¡¥ä¸€å¥ï¼š
Since this was only a functional test, I intentionally used a very small configuration (num_points=128, k=5, CPU only).
The goal was not accuracy, but to verify that the implementation runs correctly.
The full-scale experiment is currently running on my MacBook and I will add the final results once training finishes.
è¿™å¥è¯å¾ˆä¸“ä¸šã€å¾ˆè¯šå®ï¼Œä¹Ÿç¬¦åˆ industry research workflowã€‚
ğŸŸ¡ ä»€ä¹ˆæ—¶å€™å†è¡¥ Full-scale ç»“æœï¼Ÿ
ç­‰ä½ çš„ MacBookï¼š
1024 ç‚¹ Ã— k=20
çœŸæ­£è®­ç»ƒä¸€è½®
å¾—åˆ° ~90%+ accuracy
ğŸ‘‰ ä½ åªéœ€è¦ï¼š
æŠŠæ•°å€¼æ›¿æ¢åˆ° PPT
åŠ ä¸€å¼  loss/acc æ›²çº¿å›¾ï¼ˆå¯é€‰ï¼‰
å°è§„æ¨¡æµ‹è¯•ç»“æœä¿ç•™åœ¨ PPT ä¸­ä¹Ÿå¾ˆåŠ åˆ†ï¼Œå› ä¸ºå®ƒä½“ç°ï¼š
ä½ ä¸æ˜¯ç›²ç›®è·‘å®éªŒ
è€Œæ˜¯é€æ­¥éªŒè¯ pipeline
ğŸ“Œ å°å»ºè®®ï¼ˆç°åœ¨å°±èƒ½åšï¼‰
åœ¨ Page 8 çš„æœ€ä¸‹é¢åŠ ä¸€ä¸ªå ä½å—ï¼š
Full-scale experiment (in progress):
num_points = 1024
k = 20
Expected: ~90%+ accuracy (according to paper)
I will update the final results once the current training run finishes.
è¿™æ ·å¯¼å¸ˆçœ‹åˆ°ï¼š
ä½ å·²ç»å¼€å§‹â€œæ­£å¼å¤ç°å®éªŒâ€
ç°åœ¨å¤„äºåˆç†é˜¶æ®µ