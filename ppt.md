æ¨è PPT ç»“æ„ï¼ˆ10â€“14 é¡µï¼‰
æˆ‘ç»™ä½ ä¸€ä¸ªå®ç”¨ç»“æ„ï¼Œæ¯ä¸€é¡µéƒ½å†™ä¸Šã€Œè¦è®²çš„é‡ç‚¹ã€ã€‚
â­ å°é¢é¡µ
Titleï¼šDGCNN Paper Reproduction â€” Understanding & Implementation
Name / Date
Mentor nameï¼ˆå¯é€‰ï¼‰
ğŸ‘‰ æ˜¾å¾—æ­£å¼
â­ Page 1 â€” Background & Task Objective
å†…å®¹è¦ç®€çŸ­ï¼š
What is the task?
3D Point Cloud Classification / Segmentation
Why DGCNN matters?
Local geometric relationships
Dynamic neighborhood learning
My task:
Reproduce code
Understand model
Run experiments & report insights
ğŸ‘‰ ç”¨ 3ï½4 bulletï¼Œä¸è¦å †å­—
â­ Page 2 â€” Paper Overviewï¼ˆæ ¸å¿ƒæ€æƒ³ï¼‰
å»ºè®®ç”» ä¸€å¼ é€»è¾‘å›¾ï¼ˆä½ è‡ªå·±ç”»å³å¯ï¼‰ï¼š
åŒ…æ‹¬ï¼š
è¾“å…¥ï¼šç‚¹äº‘ 
N
Ã—
3
NÃ—3
KNN æ„å›¾
EdgeConv æå–è¾¹ç‰¹å¾
å¤šå±‚å †å 
Global pooling
å¹¶åŠ ä¸€å¥æ€»ç»“ï¼š
Key idea: Learn features on dynamic graphs instead of static neighborhoods.
ğŸ‘‰ è¿™ä¸€é¡µæ˜¯â€œå±•ç¤ºä½ ç†è§£è®ºæ–‡â€çš„å…³é”®
â­ Page 3 â€” EdgeConv Explainedï¼ˆå¿…é¡»è®²æ¸…ï¼‰
å†…å®¹ï¼š
edge feature = 
h
(
x
i
,
x
j
âˆ’
x
i
)
h(x 
i
â€‹	
 ,x 
j
â€‹	
 âˆ’x 
i
â€‹	
 )
Preserve:
local geometry
translation awareness
Aggregation via max-pooling
å³ä¾§æ”¾ä¸€å°å¼ ç¤ºæ„æ¡†å›¾å³å¯ã€‚
ğŸ‘‰ è¿™ä¸€é¡µæ˜¯ mentor æœ€å¯èƒ½é—®é—®é¢˜çš„åœ°æ–¹
â­ Page 4 â€” Dynamic Graph vs Static Graph
ä¸¤æ å¯¹æ¯”è¡¨ï¼š
Static Graph	Dynamic Graph
fixed based on xyz	rebuilt per layer
same neighbors	feature-space neighbors
weak semantics	stronger semantics
æœ€åä¸€å¥æ€»ç»“ï¼š
Dynamic graph helps high-level semantic grouping.
ğŸ‘‰ ä½“ç°â€œç†è§£åˆ°ä½ï¼Œè€Œä¸æ˜¯æœºæ¢°å¤ç°â€
â­ Page 5 â€” Repository Structure (PyTorch Version)
åˆ—å‡º pytorch ç›®å½•å¯¹åº”å…³ç³»ï¼š
Component	File
Data loading	data.py
Model (EdgeConv)	model.py
Training loop	main.py
Utilities	util.py
å†åŠ ä¸€å¥ï¼š
I focused on PyTorch for main reproduction and understanding.
ğŸ‘‰ è¿™æ˜¯â€œä»£ç å±‚ç†è§£â€çš„èµ·ç‚¹
â­ Page 6 â€” Codeâ€“Paper Mappingï¼ˆåŠ åˆ†é¡µğŸ”¥ï¼‰
åšä¸€ä¸ªéå¸¸åŠ åˆ†çš„è¡¨ï¼š
Paper Concept	Code Implementation
EdgeConv	get_graph_feature() + EdgeConv()
Dynamic KNN	knn(x, k) called in each layer
Feature aggregation	concatenation across EdgeConv layers
Global representation	x.max(dim=2)
ğŸ‘‰ è¿™ä¸€é¡µå¯¼å¸ˆéå¸¸å–œæ¬¢
â­ Page 7 â€” Engineering Work I Didï¼ˆéå¸¸å…³é”®ï¼‰
è¿™ä¸€é¡µä¸€å®šè¦å†™ä½ â€œè‡ªå·±åšäº†ä»€ä¹ˆâ€ï¼š
Manual dataset preparation
Modify shell commands â†’ cross-platform (mac/Windows)
CPU-only environment setup
Small-scale sanity test
Logging & reproducibility scripts
ğŸ‘‰ è¿™æ˜¯æŠŠä½ ä»â€œå­¦ç”Ÿâ€å‡çº§åˆ°â€œå·¥ç¨‹å®ä¹ ç”Ÿâ€çš„åœ°æ–¹
â­ Page 8 â€” PyTorch Experiment Setupï¼ˆè®­ç»ƒä¸­å¯ç•™ç©ºï¼‰
å†…å®¹å¯ä»¥å…ˆå†™æ¡†æ¶ï¼Œç»“æœæ˜å¤©è¡¥ï¼š
ModelNet40
num_points=1024
k=20
optimizer: SGD
batch size / epochs
ç•™ä¸€ä¸ªå ä½ï¼š
Training in progressâ€¦
Test Accuracy:  xx.xx %  (to be filled)
Loss curve: (graph to insert)
ğŸ‘‰ ä½ å¯ä»¥ç­‰è®­ç»ƒç»“æŸå†è¡¥å›¾
â­ Page 9 â€” TensorFlow Version (Brief Study)
å†™ä¸‰ç‚¹å³å¯ï¼š
Static graph (session-based) pipeline
Similar model structure, different framework style
I ran a small-scale experiment to compare behavior
å¯ä»¥å†™ï¼š
I mainly used TF version for structural comparison, not full reproduction.
ğŸ‘‰ å±•ç° breadthï¼Œä¸ç”¨èŠ±å¤ªå¤šç¯‡å¹…
â­ Page 10 â€” Comparison PyTorch vs TensorFlowï¼ˆç®€çŸ­ï¼‰
PyTorch	TensorFlow
easier debugging	harder debugging
dynamic graph	static graph
better for research iteration	closer to early original code
I used for reproduction	I used for reference
ğŸ‘‰ å¯¼å¸ˆä¼šè§‰å¾—ä½ â€œæœ‰åˆ¤æ–­ã€æœ‰é€‰æ‹©â€
â­ Page 11 â€” What I Learned
å†™åæ€å‹æ€»ç»“ï¼š
Understanding graph-based feature learning
Difference between implementation & paper abstraction
Practical issues in reproducibility
Trade-off: CPU-only vs speed
ğŸ‘‰ æ˜¯ä¸€é¡µ æˆç†Ÿã€è¯šå®ã€æœ‰æ€è€ƒ çš„æ€»ç»“
â­ Page 12 â€” Next Stepsï¼ˆå¯¼å¸ˆè®¨è®ºå…¥å£ï¼‰
å†™ 3ï½4 æ¡å³å¯ï¼š
Ablation:
static vs dynamic graph
Try segmentation experiment
Visualize neighborhood evolution
Try larger-scale full training
ğŸ‘‰ ç»™ mentor æä¾›â€œè®¨è®ºè¯é¢˜â€
ğŸ› ï¸ ä½ ç°åœ¨å¯ä»¥è¿™æ ·å®‰æ’å·¥ä½œ
ä»Šæ™š / æ˜æ—©ï¼š
1ï¸âƒ£ å¼€å§‹è·‘ PyTorch 1024 full trainingï¼ˆCPUç‰ˆï¼‰
2ï¸âƒ£ è·‘ä¸€ä¸ª å°è§„æ¨¡ TensorFlow run
3ï¸âƒ£ åŒæ—¶å®Œæˆ PPT çš„å‰ 10 é¡µï¼ˆä¸å«ç»“æœï¼‰
ç­‰è®­ç»ƒå®Œæˆï¼š
4ï¸âƒ£ æŠŠï¼š
test accuracy
loss curve
few logs / screenshots
å¡«å…¥ Page 8
